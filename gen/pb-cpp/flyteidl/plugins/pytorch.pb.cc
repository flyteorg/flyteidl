// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: flyteidl/plugins/pytorch.proto

#include "flyteidl/plugins/pytorch.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG
namespace flyteidl {
namespace plugins {
constexpr DistributedPyTorchTrainingTask::DistributedPyTorchTrainingTask(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : workers_(0){}
struct DistributedPyTorchTrainingTaskDefaultTypeInternal {
  constexpr DistributedPyTorchTrainingTaskDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~DistributedPyTorchTrainingTaskDefaultTypeInternal() {}
  union {
    DistributedPyTorchTrainingTask _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT DistributedPyTorchTrainingTaskDefaultTypeInternal _DistributedPyTorchTrainingTask_default_instance_;
}  // namespace plugins
}  // namespace flyteidl
static ::PROTOBUF_NAMESPACE_ID::Metadata file_level_metadata_flyteidl_2fplugins_2fpytorch_2eproto[1];
static constexpr ::PROTOBUF_NAMESPACE_ID::EnumDescriptor const** file_level_enum_descriptors_flyteidl_2fplugins_2fpytorch_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_flyteidl_2fplugins_2fpytorch_2eproto = nullptr;

const uint32_t TableStruct_flyteidl_2fplugins_2fpytorch_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::flyteidl::plugins::DistributedPyTorchTrainingTask, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::flyteidl::plugins::DistributedPyTorchTrainingTask, workers_),
};
static const ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::flyteidl::plugins::DistributedPyTorchTrainingTask)},
};

static ::PROTOBUF_NAMESPACE_ID::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::flyteidl::plugins::_DistributedPyTorchTrainingTask_default_instance_),
};

const char descriptor_table_protodef_flyteidl_2fplugins_2fpytorch_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n\036flyteidl/plugins/pytorch.proto\022\020flytei"
  "dl.plugins\":\n\036DistributedPyTorchTraining"
  "Task\022\030\n\007workers\030\001 \001(\005R\007workersB\301\001\n\024com.f"
  "lyteidl.pluginsB\014PytorchProtoH\002Z7github."
  "com/flyteorg/flyteidl/gen/pb-go/flyteidl"
  "/plugins\370\001\000\242\002\003FPX\252\002\020Flyteidl.Plugins\312\002\020F"
  "lyteidl\\Plugins\342\002\034Flyteidl\\Plugins\\GPBMe"
  "tadata\352\002\021Flyteidl::Pluginsb\006proto3"
  ;
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto = {
  false, false, 314, descriptor_table_protodef_flyteidl_2fplugins_2fpytorch_2eproto, "flyteidl/plugins/pytorch.proto", 
  &descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto_once, nullptr, 0, 1,
  schemas, file_default_instances, TableStruct_flyteidl_2fplugins_2fpytorch_2eproto::offsets,
  file_level_metadata_flyteidl_2fplugins_2fpytorch_2eproto, file_level_enum_descriptors_flyteidl_2fplugins_2fpytorch_2eproto, file_level_service_descriptors_flyteidl_2fplugins_2fpytorch_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable* descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto_getter() {
  return &descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY static ::PROTOBUF_NAMESPACE_ID::internal::AddDescriptorsRunner dynamic_init_dummy_flyteidl_2fplugins_2fpytorch_2eproto(&descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto);
namespace flyteidl {
namespace plugins {

// ===================================================================

class DistributedPyTorchTrainingTask::_Internal {
 public:
};

DistributedPyTorchTrainingTask::DistributedPyTorchTrainingTask(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:flyteidl.plugins.DistributedPyTorchTrainingTask)
}
DistributedPyTorchTrainingTask::DistributedPyTorchTrainingTask(const DistributedPyTorchTrainingTask& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  workers_ = from.workers_;
  // @@protoc_insertion_point(copy_constructor:flyteidl.plugins.DistributedPyTorchTrainingTask)
}

inline void DistributedPyTorchTrainingTask::SharedCtor() {
workers_ = 0;
}

DistributedPyTorchTrainingTask::~DistributedPyTorchTrainingTask() {
  // @@protoc_insertion_point(destructor:flyteidl.plugins.DistributedPyTorchTrainingTask)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void DistributedPyTorchTrainingTask::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void DistributedPyTorchTrainingTask::ArenaDtor(void* object) {
  DistributedPyTorchTrainingTask* _this = reinterpret_cast< DistributedPyTorchTrainingTask* >(object);
  (void)_this;
}
void DistributedPyTorchTrainingTask::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void DistributedPyTorchTrainingTask::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void DistributedPyTorchTrainingTask::InternalSwap(DistributedPyTorchTrainingTask* other) {
  using std::swap;
  GetReflection()->Swap(this, other);}

::PROTOBUF_NAMESPACE_ID::Metadata DistributedPyTorchTrainingTask::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto_getter, &descriptor_table_flyteidl_2fplugins_2fpytorch_2eproto_once,
      file_level_metadata_flyteidl_2fplugins_2fpytorch_2eproto[0]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace plugins
}  // namespace flyteidl
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::flyteidl::plugins::DistributedPyTorchTrainingTask* Arena::CreateMaybeMessage< ::flyteidl::plugins::DistributedPyTorchTrainingTask >(Arena* arena) {
  return Arena::CreateMessageInternal< ::flyteidl::plugins::DistributedPyTorchTrainingTask >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
