// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: flyteidl/plugins/spark.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_flyteidl_2fplugins_2fspark_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_flyteidl_2fplugins_2fspark_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3019000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3019004 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_bases.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/map.h>  // IWYU pragma: export
#include <google/protobuf/map_entry.h>
#include <google/protobuf/map_field_inl.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_flyteidl_2fplugins_2fspark_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_flyteidl_2fplugins_2fspark_2eproto {
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTableField entries[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::AuxiliaryParseTableField aux[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTable schema[4]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::FieldMetadata field_metadata[];
  static const ::PROTOBUF_NAMESPACE_ID::internal::SerializationTable serialization_table[];
  static const uint32_t offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_flyteidl_2fplugins_2fspark_2eproto;
namespace flyteidl {
namespace plugins {
class SparkApplication;
struct SparkApplicationDefaultTypeInternal;
extern SparkApplicationDefaultTypeInternal _SparkApplication_default_instance_;
class SparkJob;
struct SparkJobDefaultTypeInternal;
extern SparkJobDefaultTypeInternal _SparkJob_default_instance_;
class SparkJob_HadoopConfEntry_DoNotUse;
struct SparkJob_HadoopConfEntry_DoNotUseDefaultTypeInternal;
extern SparkJob_HadoopConfEntry_DoNotUseDefaultTypeInternal _SparkJob_HadoopConfEntry_DoNotUse_default_instance_;
class SparkJob_SparkConfEntry_DoNotUse;
struct SparkJob_SparkConfEntry_DoNotUseDefaultTypeInternal;
extern SparkJob_SparkConfEntry_DoNotUseDefaultTypeInternal _SparkJob_SparkConfEntry_DoNotUse_default_instance_;
}  // namespace plugins
}  // namespace flyteidl
PROTOBUF_NAMESPACE_OPEN
template<> ::flyteidl::plugins::SparkApplication* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkApplication>(Arena*);
template<> ::flyteidl::plugins::SparkJob* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkJob>(Arena*);
template<> ::flyteidl::plugins::SparkJob_HadoopConfEntry_DoNotUse* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkJob_HadoopConfEntry_DoNotUse>(Arena*);
template<> ::flyteidl::plugins::SparkJob_SparkConfEntry_DoNotUse* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkJob_SparkConfEntry_DoNotUse>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace flyteidl {
namespace plugins {

enum SparkApplication_Type : int {
  SparkApplication_Type_PYTHON = 0,
  SparkApplication_Type_JAVA = 1,
  SparkApplication_Type_SCALA = 2,
  SparkApplication_Type_R = 3,
  SparkApplication_Type_SparkApplication_Type_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::min(),
  SparkApplication_Type_SparkApplication_Type_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::max()
};
bool SparkApplication_Type_IsValid(int value);
constexpr SparkApplication_Type SparkApplication_Type_Type_MIN = SparkApplication_Type_PYTHON;
constexpr SparkApplication_Type SparkApplication_Type_Type_MAX = SparkApplication_Type_R;
constexpr int SparkApplication_Type_Type_ARRAYSIZE = SparkApplication_Type_Type_MAX + 1;

const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* SparkApplication_Type_descriptor();
template<typename T>
inline const std::string& SparkApplication_Type_Name(T enum_t_value) {
  static_assert(::std::is_same<T, SparkApplication_Type>::value ||
    ::std::is_integral<T>::value,
    "Incorrect type passed to function SparkApplication_Type_Name.");
  return ::PROTOBUF_NAMESPACE_ID::internal::NameOfEnum(
    SparkApplication_Type_descriptor(), enum_t_value);
}
inline bool SparkApplication_Type_Parse(
    ::PROTOBUF_NAMESPACE_ID::ConstStringParam name, SparkApplication_Type* value) {
  return ::PROTOBUF_NAMESPACE_ID::internal::ParseNamedEnum<SparkApplication_Type>(
    SparkApplication_Type_descriptor(), name, value);
}
// ===================================================================

class SparkApplication final :
    public ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase /* @@protoc_insertion_point(class_definition:flyteidl.plugins.SparkApplication) */ {
 public:
  inline SparkApplication() : SparkApplication(nullptr) {}
  explicit constexpr SparkApplication(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  SparkApplication(const SparkApplication& from);
  SparkApplication(SparkApplication&& from) noexcept
    : SparkApplication() {
    *this = ::std::move(from);
  }

  inline SparkApplication& operator=(const SparkApplication& from) {
    CopyFrom(from);
    return *this;
  }
  inline SparkApplication& operator=(SparkApplication&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const SparkApplication& default_instance() {
    return *internal_default_instance();
  }
  static inline const SparkApplication* internal_default_instance() {
    return reinterpret_cast<const SparkApplication*>(
               &_SparkApplication_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(SparkApplication& a, SparkApplication& b) {
    a.Swap(&b);
  }
  inline void Swap(SparkApplication* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(SparkApplication* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  SparkApplication* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<SparkApplication>(arena);
  }

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "flyteidl.plugins.SparkApplication";
  }
  protected:
  explicit SparkApplication(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef SparkApplication_Type Type;
  static constexpr Type PYTHON =
    SparkApplication_Type_PYTHON;
  static constexpr Type JAVA =
    SparkApplication_Type_JAVA;
  static constexpr Type SCALA =
    SparkApplication_Type_SCALA;
  static constexpr Type R =
    SparkApplication_Type_R;
  static inline bool Type_IsValid(int value) {
    return SparkApplication_Type_IsValid(value);
  }
  static constexpr Type Type_MIN =
    SparkApplication_Type_Type_MIN;
  static constexpr Type Type_MAX =
    SparkApplication_Type_Type_MAX;
  static constexpr int Type_ARRAYSIZE =
    SparkApplication_Type_Type_ARRAYSIZE;
  static inline const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor*
  Type_descriptor() {
    return SparkApplication_Type_descriptor();
  }
  template<typename T>
  static inline const std::string& Type_Name(T enum_t_value) {
    static_assert(::std::is_same<T, Type>::value ||
      ::std::is_integral<T>::value,
      "Incorrect type passed to function Type_Name.");
    return SparkApplication_Type_Name(enum_t_value);
  }
  static inline bool Type_Parse(::PROTOBUF_NAMESPACE_ID::ConstStringParam name,
      Type* value) {
    return SparkApplication_Type_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:flyteidl.plugins.SparkApplication)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_flyteidl_2fplugins_2fspark_2eproto;
};
// -------------------------------------------------------------------

class SparkJob_SparkConfEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<SparkJob_SparkConfEntry_DoNotUse, 
    std::string, std::string,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<SparkJob_SparkConfEntry_DoNotUse, 
    std::string, std::string,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING> SuperType;
  SparkJob_SparkConfEntry_DoNotUse();
  explicit constexpr SparkJob_SparkConfEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit SparkJob_SparkConfEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const SparkJob_SparkConfEntry_DoNotUse& other);
  static const SparkJob_SparkConfEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const SparkJob_SparkConfEntry_DoNotUse*>(&_SparkJob_SparkConfEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "flyteidl.plugins.SparkJob.SparkConfEntry.key");
 }
  static bool ValidateValue(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "flyteidl.plugins.SparkJob.SparkConfEntry.value");
 }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
};

// -------------------------------------------------------------------

class SparkJob_HadoopConfEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<SparkJob_HadoopConfEntry_DoNotUse, 
    std::string, std::string,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<SparkJob_HadoopConfEntry_DoNotUse, 
    std::string, std::string,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING> SuperType;
  SparkJob_HadoopConfEntry_DoNotUse();
  explicit constexpr SparkJob_HadoopConfEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit SparkJob_HadoopConfEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const SparkJob_HadoopConfEntry_DoNotUse& other);
  static const SparkJob_HadoopConfEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const SparkJob_HadoopConfEntry_DoNotUse*>(&_SparkJob_HadoopConfEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "flyteidl.plugins.SparkJob.HadoopConfEntry.key");
 }
  static bool ValidateValue(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "flyteidl.plugins.SparkJob.HadoopConfEntry.value");
 }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
};

// -------------------------------------------------------------------

class SparkJob final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:flyteidl.plugins.SparkJob) */ {
 public:
  inline SparkJob() : SparkJob(nullptr) {}
  ~SparkJob() override;
  explicit constexpr SparkJob(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  SparkJob(const SparkJob& from);
  SparkJob(SparkJob&& from) noexcept
    : SparkJob() {
    *this = ::std::move(from);
  }

  inline SparkJob& operator=(const SparkJob& from) {
    CopyFrom(from);
    return *this;
  }
  inline SparkJob& operator=(SparkJob&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const SparkJob& default_instance() {
    return *internal_default_instance();
  }
  static inline const SparkJob* internal_default_instance() {
    return reinterpret_cast<const SparkJob*>(
               &_SparkJob_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  friend void swap(SparkJob& a, SparkJob& b) {
    a.Swap(&b);
  }
  inline void Swap(SparkJob* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(SparkJob* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  SparkJob* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<SparkJob>(arena);
  }
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SparkJob* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "flyteidl.plugins.SparkJob";
  }
  protected:
  explicit SparkJob(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  enum : int {
    kSparkConfFieldNumber = 4,
    kHadoopConfFieldNumber = 5,
    kMainApplicationFileFieldNumber = 2,
    kMainClassFieldNumber = 3,
    kExecutorPathFieldNumber = 6,
    kApplicationTypeFieldNumber = 1,
  };
  // map<string, string> sparkConf = 4 [json_name = "sparkConf"];
  int sparkconf_size() const;
  private:
  int _internal_sparkconf_size() const;
  public:
  void clear_sparkconf();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
      _internal_sparkconf() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
      _internal_mutable_sparkconf();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
      sparkconf() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
      mutable_sparkconf();

  // map<string, string> hadoopConf = 5 [json_name = "hadoopConf"];
  int hadoopconf_size() const;
  private:
  int _internal_hadoopconf_size() const;
  public:
  void clear_hadoopconf();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
      _internal_hadoopconf() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
      _internal_mutable_hadoopconf();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
      hadoopconf() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
      mutable_hadoopconf();

  // string mainApplicationFile = 2 [json_name = "mainApplicationFile"];
  void clear_mainapplicationfile();
  const std::string& mainapplicationfile() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_mainapplicationfile(ArgT0&& arg0, ArgT... args);
  std::string* mutable_mainapplicationfile();
  PROTOBUF_NODISCARD std::string* release_mainapplicationfile();
  void set_allocated_mainapplicationfile(std::string* mainapplicationfile);
  private:
  const std::string& _internal_mainapplicationfile() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_mainapplicationfile(const std::string& value);
  std::string* _internal_mutable_mainapplicationfile();
  public:

  // string mainClass = 3 [json_name = "mainClass"];
  void clear_mainclass();
  const std::string& mainclass() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_mainclass(ArgT0&& arg0, ArgT... args);
  std::string* mutable_mainclass();
  PROTOBUF_NODISCARD std::string* release_mainclass();
  void set_allocated_mainclass(std::string* mainclass);
  private:
  const std::string& _internal_mainclass() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_mainclass(const std::string& value);
  std::string* _internal_mutable_mainclass();
  public:

  // string executorPath = 6 [json_name = "executorPath"];
  void clear_executorpath();
  const std::string& executorpath() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_executorpath(ArgT0&& arg0, ArgT... args);
  std::string* mutable_executorpath();
  PROTOBUF_NODISCARD std::string* release_executorpath();
  void set_allocated_executorpath(std::string* executorpath);
  private:
  const std::string& _internal_executorpath() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_executorpath(const std::string& value);
  std::string* _internal_mutable_executorpath();
  public:

  // .flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];
  void clear_applicationtype();
  ::flyteidl::plugins::SparkApplication_Type applicationtype() const;
  void set_applicationtype(::flyteidl::plugins::SparkApplication_Type value);
  private:
  ::flyteidl::plugins::SparkApplication_Type _internal_applicationtype() const;
  void _internal_set_applicationtype(::flyteidl::plugins::SparkApplication_Type value);
  public:

  // @@protoc_insertion_point(class_scope:flyteidl.plugins.SparkJob)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::MapField<
      SparkJob_SparkConfEntry_DoNotUse,
      std::string, std::string,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING> sparkconf_;
  ::PROTOBUF_NAMESPACE_ID::internal::MapField<
      SparkJob_HadoopConfEntry_DoNotUse,
      std::string, std::string,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING> hadoopconf_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr mainapplicationfile_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr mainclass_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr executorpath_;
  int applicationtype_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_flyteidl_2fplugins_2fspark_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// SparkApplication

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// SparkJob

// .flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];
inline void SparkJob::clear_applicationtype() {
  applicationtype_ = 0;
}
inline ::flyteidl::plugins::SparkApplication_Type SparkJob::_internal_applicationtype() const {
  return static_cast< ::flyteidl::plugins::SparkApplication_Type >(applicationtype_);
}
inline ::flyteidl::plugins::SparkApplication_Type SparkJob::applicationtype() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.applicationType)
  return _internal_applicationtype();
}
inline void SparkJob::_internal_set_applicationtype(::flyteidl::plugins::SparkApplication_Type value) {
  
  applicationtype_ = value;
}
inline void SparkJob::set_applicationtype(::flyteidl::plugins::SparkApplication_Type value) {
  _internal_set_applicationtype(value);
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.applicationType)
}

// string mainApplicationFile = 2 [json_name = "mainApplicationFile"];
inline void SparkJob::clear_mainapplicationfile() {
  mainapplicationfile_.ClearToEmpty();
}
inline const std::string& SparkJob::mainapplicationfile() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.mainApplicationFile)
  return _internal_mainapplicationfile();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void SparkJob::set_mainapplicationfile(ArgT0&& arg0, ArgT... args) {
 
 mainapplicationfile_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.mainApplicationFile)
}
inline std::string* SparkJob::mutable_mainapplicationfile() {
  std::string* _s = _internal_mutable_mainapplicationfile();
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.mainApplicationFile)
  return _s;
}
inline const std::string& SparkJob::_internal_mainapplicationfile() const {
  return mainapplicationfile_.Get();
}
inline void SparkJob::_internal_set_mainapplicationfile(const std::string& value) {
  
  mainapplicationfile_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* SparkJob::_internal_mutable_mainapplicationfile() {
  
  return mainapplicationfile_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* SparkJob::release_mainapplicationfile() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.mainApplicationFile)
  return mainapplicationfile_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void SparkJob::set_allocated_mainapplicationfile(std::string* mainapplicationfile) {
  if (mainapplicationfile != nullptr) {
    
  } else {
    
  }
  mainapplicationfile_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), mainapplicationfile,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (mainapplicationfile_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    mainapplicationfile_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.mainApplicationFile)
}

// string mainClass = 3 [json_name = "mainClass"];
inline void SparkJob::clear_mainclass() {
  mainclass_.ClearToEmpty();
}
inline const std::string& SparkJob::mainclass() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.mainClass)
  return _internal_mainclass();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void SparkJob::set_mainclass(ArgT0&& arg0, ArgT... args) {
 
 mainclass_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.mainClass)
}
inline std::string* SparkJob::mutable_mainclass() {
  std::string* _s = _internal_mutable_mainclass();
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.mainClass)
  return _s;
}
inline const std::string& SparkJob::_internal_mainclass() const {
  return mainclass_.Get();
}
inline void SparkJob::_internal_set_mainclass(const std::string& value) {
  
  mainclass_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* SparkJob::_internal_mutable_mainclass() {
  
  return mainclass_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* SparkJob::release_mainclass() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.mainClass)
  return mainclass_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void SparkJob::set_allocated_mainclass(std::string* mainclass) {
  if (mainclass != nullptr) {
    
  } else {
    
  }
  mainclass_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), mainclass,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (mainclass_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    mainclass_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.mainClass)
}

// map<string, string> sparkConf = 4 [json_name = "sparkConf"];
inline int SparkJob::_internal_sparkconf_size() const {
  return sparkconf_.size();
}
inline int SparkJob::sparkconf_size() const {
  return _internal_sparkconf_size();
}
inline void SparkJob::clear_sparkconf() {
  sparkconf_.Clear();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
SparkJob::_internal_sparkconf() const {
  return sparkconf_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
SparkJob::sparkconf() const {
  // @@protoc_insertion_point(field_map:flyteidl.plugins.SparkJob.sparkConf)
  return _internal_sparkconf();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
SparkJob::_internal_mutable_sparkconf() {
  return sparkconf_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
SparkJob::mutable_sparkconf() {
  // @@protoc_insertion_point(field_mutable_map:flyteidl.plugins.SparkJob.sparkConf)
  return _internal_mutable_sparkconf();
}

// map<string, string> hadoopConf = 5 [json_name = "hadoopConf"];
inline int SparkJob::_internal_hadoopconf_size() const {
  return hadoopconf_.size();
}
inline int SparkJob::hadoopconf_size() const {
  return _internal_hadoopconf_size();
}
inline void SparkJob::clear_hadoopconf() {
  hadoopconf_.Clear();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
SparkJob::_internal_hadoopconf() const {
  return hadoopconf_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >&
SparkJob::hadoopconf() const {
  // @@protoc_insertion_point(field_map:flyteidl.plugins.SparkJob.hadoopConf)
  return _internal_hadoopconf();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
SparkJob::_internal_mutable_hadoopconf() {
  return hadoopconf_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >*
SparkJob::mutable_hadoopconf() {
  // @@protoc_insertion_point(field_mutable_map:flyteidl.plugins.SparkJob.hadoopConf)
  return _internal_mutable_hadoopconf();
}

// string executorPath = 6 [json_name = "executorPath"];
inline void SparkJob::clear_executorpath() {
  executorpath_.ClearToEmpty();
}
inline const std::string& SparkJob::executorpath() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.executorPath)
  return _internal_executorpath();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void SparkJob::set_executorpath(ArgT0&& arg0, ArgT... args) {
 
 executorpath_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.executorPath)
}
inline std::string* SparkJob::mutable_executorpath() {
  std::string* _s = _internal_mutable_executorpath();
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.executorPath)
  return _s;
}
inline const std::string& SparkJob::_internal_executorpath() const {
  return executorpath_.Get();
}
inline void SparkJob::_internal_set_executorpath(const std::string& value) {
  
  executorpath_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* SparkJob::_internal_mutable_executorpath() {
  
  return executorpath_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* SparkJob::release_executorpath() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.executorPath)
  return executorpath_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void SparkJob::set_allocated_executorpath(std::string* executorpath) {
  if (executorpath != nullptr) {
    
  } else {
    
  }
  executorpath_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), executorpath,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (executorpath_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    executorpath_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.executorPath)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace plugins
}  // namespace flyteidl

PROTOBUF_NAMESPACE_OPEN

template <> struct is_proto_enum< ::flyteidl::plugins::SparkApplication_Type> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::flyteidl::plugins::SparkApplication_Type>() {
  return ::flyteidl::plugins::SparkApplication_Type_descriptor();
}

PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_flyteidl_2fplugins_2fspark_2eproto
