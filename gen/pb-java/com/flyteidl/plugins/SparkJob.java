// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: flyteidl/plugins/spark.proto

package com.flyteidl.plugins;

/**
 * <pre>
 * Custom Proto for Spark Plugin.
 * </pre>
 *
 * Protobuf type {@code flyteidl.plugins.SparkJob}
 */
public final class SparkJob extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:flyteidl.plugins.SparkJob)
    SparkJobOrBuilder {
private static final long serialVersionUID = 0L;
  // Use SparkJob.newBuilder() to construct.
  private SparkJob(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private SparkJob() {
    applicationType_ = 0;
    mainApplicationFile_ = "";
    mainClass_ = "";
    executorPath_ = "";
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(
      UnusedPrivateParameter unused) {
    return new SparkJob();
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return this.unknownFields;
  }
  private SparkJob(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    if (extensionRegistry == null) {
      throw new java.lang.NullPointerException();
    }
    int mutable_bitField0_ = 0;
    com.google.protobuf.UnknownFieldSet.Builder unknownFields =
        com.google.protobuf.UnknownFieldSet.newBuilder();
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          case 8: {
            int rawValue = input.readEnum();

            applicationType_ = rawValue;
            break;
          }
          case 18: {
            java.lang.String s = input.readStringRequireUtf8();

            mainApplicationFile_ = s;
            break;
          }
          case 26: {
            java.lang.String s = input.readStringRequireUtf8();

            mainClass_ = s;
            break;
          }
          case 34: {
            if (!((mutable_bitField0_ & 0x00000001) != 0)) {
              sparkConf_ = com.google.protobuf.MapField.newMapField(
                  SparkConfDefaultEntryHolder.defaultEntry);
              mutable_bitField0_ |= 0x00000001;
            }
            com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
            sparkConf__ = input.readMessage(
                SparkConfDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
            sparkConf_.getMutableMap().put(
                sparkConf__.getKey(), sparkConf__.getValue());
            break;
          }
          case 42: {
            if (!((mutable_bitField0_ & 0x00000002) != 0)) {
              hadoopConf_ = com.google.protobuf.MapField.newMapField(
                  HadoopConfDefaultEntryHolder.defaultEntry);
              mutable_bitField0_ |= 0x00000002;
            }
            com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
            hadoopConf__ = input.readMessage(
                HadoopConfDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
            hadoopConf_.getMutableMap().put(
                hadoopConf__.getKey(), hadoopConf__.getValue());
            break;
          }
          case 50: {
            java.lang.String s = input.readStringRequireUtf8();

            executorPath_ = s;
            break;
          }
          default: {
            if (!parseUnknownField(
                input, unknownFields, extensionRegistry, tag)) {
              done = true;
            }
            break;
          }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(
          e).setUnfinishedMessage(this);
    } finally {
      this.unknownFields = unknownFields.build();
      makeExtensionsImmutable();
    }
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_descriptor;
  }

  @SuppressWarnings({"rawtypes"})
  @java.lang.Override
  protected com.google.protobuf.MapField internalGetMapField(
      int number) {
    switch (number) {
      case 4:
        return internalGetSparkConf();
      case 5:
        return internalGetHadoopConf();
      default:
        throw new RuntimeException(
            "Invalid map field number: " + number);
    }
  }
  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.flyteidl.plugins.SparkJob.class, com.flyteidl.plugins.SparkJob.Builder.class);
  }

  public static final int APPLICATIONTYPE_FIELD_NUMBER = 1;
  private int applicationType_;
  /**
   * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
   * @return The enum numeric value on the wire for applicationType.
   */
  @java.lang.Override public int getApplicationTypeValue() {
    return applicationType_;
  }
  /**
   * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
   * @return The applicationType.
   */
  @java.lang.Override public com.flyteidl.plugins.SparkApplication.Type getApplicationType() {
    @SuppressWarnings("deprecation")
    com.flyteidl.plugins.SparkApplication.Type result = com.flyteidl.plugins.SparkApplication.Type.valueOf(applicationType_);
    return result == null ? com.flyteidl.plugins.SparkApplication.Type.UNRECOGNIZED : result;
  }

  public static final int MAINAPPLICATIONFILE_FIELD_NUMBER = 2;
  private volatile java.lang.Object mainApplicationFile_;
  /**
   * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
   * @return The mainApplicationFile.
   */
  @java.lang.Override
  public java.lang.String getMainApplicationFile() {
    java.lang.Object ref = mainApplicationFile_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      mainApplicationFile_ = s;
      return s;
    }
  }
  /**
   * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
   * @return The bytes for mainApplicationFile.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getMainApplicationFileBytes() {
    java.lang.Object ref = mainApplicationFile_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      mainApplicationFile_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int MAINCLASS_FIELD_NUMBER = 3;
  private volatile java.lang.Object mainClass_;
  /**
   * <code>string mainClass = 3 [json_name = "mainClass"];</code>
   * @return The mainClass.
   */
  @java.lang.Override
  public java.lang.String getMainClass() {
    java.lang.Object ref = mainClass_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      mainClass_ = s;
      return s;
    }
  }
  /**
   * <code>string mainClass = 3 [json_name = "mainClass"];</code>
   * @return The bytes for mainClass.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getMainClassBytes() {
    java.lang.Object ref = mainClass_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      mainClass_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int SPARKCONF_FIELD_NUMBER = 4;
  private static final class SparkConfDefaultEntryHolder {
    static final com.google.protobuf.MapEntry<
        java.lang.String, java.lang.String> defaultEntry =
            com.google.protobuf.MapEntry
            .<java.lang.String, java.lang.String>newDefaultInstance(
                com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_SparkConfEntry_descriptor, 
                com.google.protobuf.WireFormat.FieldType.STRING,
                "",
                com.google.protobuf.WireFormat.FieldType.STRING,
                "");
  }
  private com.google.protobuf.MapField<
      java.lang.String, java.lang.String> sparkConf_;
  private com.google.protobuf.MapField<java.lang.String, java.lang.String>
  internalGetSparkConf() {
    if (sparkConf_ == null) {
      return com.google.protobuf.MapField.emptyMapField(
          SparkConfDefaultEntryHolder.defaultEntry);
    }
    return sparkConf_;
  }

  public int getSparkConfCount() {
    return internalGetSparkConf().getMap().size();
  }
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */

  @java.lang.Override
  public boolean containsSparkConf(
      java.lang.String key) {
    if (key == null) { throw new NullPointerException("map key"); }
    return internalGetSparkConf().getMap().containsKey(key);
  }
  /**
   * Use {@link #getSparkConfMap()} instead.
   */
  @java.lang.Override
  @java.lang.Deprecated
  public java.util.Map<java.lang.String, java.lang.String> getSparkConf() {
    return getSparkConfMap();
  }
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */
  @java.lang.Override

  public java.util.Map<java.lang.String, java.lang.String> getSparkConfMap() {
    return internalGetSparkConf().getMap();
  }
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */
  @java.lang.Override

  public java.lang.String getSparkConfOrDefault(
      java.lang.String key,
      java.lang.String defaultValue) {
    if (key == null) { throw new NullPointerException("map key"); }
    java.util.Map<java.lang.String, java.lang.String> map =
        internalGetSparkConf().getMap();
    return map.containsKey(key) ? map.get(key) : defaultValue;
  }
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */
  @java.lang.Override

  public java.lang.String getSparkConfOrThrow(
      java.lang.String key) {
    if (key == null) { throw new NullPointerException("map key"); }
    java.util.Map<java.lang.String, java.lang.String> map =
        internalGetSparkConf().getMap();
    if (!map.containsKey(key)) {
      throw new java.lang.IllegalArgumentException();
    }
    return map.get(key);
  }

  public static final int HADOOPCONF_FIELD_NUMBER = 5;
  private static final class HadoopConfDefaultEntryHolder {
    static final com.google.protobuf.MapEntry<
        java.lang.String, java.lang.String> defaultEntry =
            com.google.protobuf.MapEntry
            .<java.lang.String, java.lang.String>newDefaultInstance(
                com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_HadoopConfEntry_descriptor, 
                com.google.protobuf.WireFormat.FieldType.STRING,
                "",
                com.google.protobuf.WireFormat.FieldType.STRING,
                "");
  }
  private com.google.protobuf.MapField<
      java.lang.String, java.lang.String> hadoopConf_;
  private com.google.protobuf.MapField<java.lang.String, java.lang.String>
  internalGetHadoopConf() {
    if (hadoopConf_ == null) {
      return com.google.protobuf.MapField.emptyMapField(
          HadoopConfDefaultEntryHolder.defaultEntry);
    }
    return hadoopConf_;
  }

  public int getHadoopConfCount() {
    return internalGetHadoopConf().getMap().size();
  }
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */

  @java.lang.Override
  public boolean containsHadoopConf(
      java.lang.String key) {
    if (key == null) { throw new NullPointerException("map key"); }
    return internalGetHadoopConf().getMap().containsKey(key);
  }
  /**
   * Use {@link #getHadoopConfMap()} instead.
   */
  @java.lang.Override
  @java.lang.Deprecated
  public java.util.Map<java.lang.String, java.lang.String> getHadoopConf() {
    return getHadoopConfMap();
  }
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */
  @java.lang.Override

  public java.util.Map<java.lang.String, java.lang.String> getHadoopConfMap() {
    return internalGetHadoopConf().getMap();
  }
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */
  @java.lang.Override

  public java.lang.String getHadoopConfOrDefault(
      java.lang.String key,
      java.lang.String defaultValue) {
    if (key == null) { throw new NullPointerException("map key"); }
    java.util.Map<java.lang.String, java.lang.String> map =
        internalGetHadoopConf().getMap();
    return map.containsKey(key) ? map.get(key) : defaultValue;
  }
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */
  @java.lang.Override

  public java.lang.String getHadoopConfOrThrow(
      java.lang.String key) {
    if (key == null) { throw new NullPointerException("map key"); }
    java.util.Map<java.lang.String, java.lang.String> map =
        internalGetHadoopConf().getMap();
    if (!map.containsKey(key)) {
      throw new java.lang.IllegalArgumentException();
    }
    return map.get(key);
  }

  public static final int EXECUTORPATH_FIELD_NUMBER = 6;
  private volatile java.lang.Object executorPath_;
  /**
   * <pre>
   * Executor path for Python jobs.
   * </pre>
   *
   * <code>string executorPath = 6 [json_name = "executorPath"];</code>
   * @return The executorPath.
   */
  @java.lang.Override
  public java.lang.String getExecutorPath() {
    java.lang.Object ref = executorPath_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      executorPath_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Executor path for Python jobs.
   * </pre>
   *
   * <code>string executorPath = 6 [json_name = "executorPath"];</code>
   * @return The bytes for executorPath.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getExecutorPathBytes() {
    java.lang.Object ref = executorPath_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      executorPath_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (applicationType_ != com.flyteidl.plugins.SparkApplication.Type.PYTHON.getNumber()) {
      output.writeEnum(1, applicationType_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainApplicationFile_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 2, mainApplicationFile_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainClass_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 3, mainClass_);
    }
    com.google.protobuf.GeneratedMessageV3
      .serializeStringMapTo(
        output,
        internalGetSparkConf(),
        SparkConfDefaultEntryHolder.defaultEntry,
        4);
    com.google.protobuf.GeneratedMessageV3
      .serializeStringMapTo(
        output,
        internalGetHadoopConf(),
        HadoopConfDefaultEntryHolder.defaultEntry,
        5);
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(executorPath_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 6, executorPath_);
    }
    unknownFields.writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (applicationType_ != com.flyteidl.plugins.SparkApplication.Type.PYTHON.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(1, applicationType_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainApplicationFile_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, mainApplicationFile_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainClass_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, mainClass_);
    }
    for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
         : internalGetSparkConf().getMap().entrySet()) {
      com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
      sparkConf__ = SparkConfDefaultEntryHolder.defaultEntry.newBuilderForType()
          .setKey(entry.getKey())
          .setValue(entry.getValue())
          .build();
      size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, sparkConf__);
    }
    for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
         : internalGetHadoopConf().getMap().entrySet()) {
      com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
      hadoopConf__ = HadoopConfDefaultEntryHolder.defaultEntry.newBuilderForType()
          .setKey(entry.getKey())
          .setValue(entry.getValue())
          .build();
      size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, hadoopConf__);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(executorPath_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, executorPath_);
    }
    size += unknownFields.getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof com.flyteidl.plugins.SparkJob)) {
      return super.equals(obj);
    }
    com.flyteidl.plugins.SparkJob other = (com.flyteidl.plugins.SparkJob) obj;

    if (applicationType_ != other.applicationType_) return false;
    if (!getMainApplicationFile()
        .equals(other.getMainApplicationFile())) return false;
    if (!getMainClass()
        .equals(other.getMainClass())) return false;
    if (!internalGetSparkConf().equals(
        other.internalGetSparkConf())) return false;
    if (!internalGetHadoopConf().equals(
        other.internalGetHadoopConf())) return false;
    if (!getExecutorPath()
        .equals(other.getExecutorPath())) return false;
    if (!unknownFields.equals(other.unknownFields)) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
    hash = (53 * hash) + applicationType_;
    hash = (37 * hash) + MAINAPPLICATIONFILE_FIELD_NUMBER;
    hash = (53 * hash) + getMainApplicationFile().hashCode();
    hash = (37 * hash) + MAINCLASS_FIELD_NUMBER;
    hash = (53 * hash) + getMainClass().hashCode();
    if (!internalGetSparkConf().getMap().isEmpty()) {
      hash = (37 * hash) + SPARKCONF_FIELD_NUMBER;
      hash = (53 * hash) + internalGetSparkConf().hashCode();
    }
    if (!internalGetHadoopConf().getMap().isEmpty()) {
      hash = (37 * hash) + HADOOPCONF_FIELD_NUMBER;
      hash = (53 * hash) + internalGetHadoopConf().hashCode();
    }
    hash = (37 * hash) + EXECUTORPATH_FIELD_NUMBER;
    hash = (53 * hash) + getExecutorPath().hashCode();
    hash = (29 * hash) + unknownFields.hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static com.flyteidl.plugins.SparkJob parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.flyteidl.plugins.SparkJob parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static com.flyteidl.plugins.SparkJob parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static com.flyteidl.plugins.SparkJob parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.flyteidl.plugins.SparkJob prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Custom Proto for Spark Plugin.
   * </pre>
   *
   * Protobuf type {@code flyteidl.plugins.SparkJob}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:flyteidl.plugins.SparkJob)
      com.flyteidl.plugins.SparkJobOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 4:
          return internalGetSparkConf();
        case 5:
          return internalGetHadoopConf();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMutableMapField(
        int number) {
      switch (number) {
        case 4:
          return internalGetMutableSparkConf();
        case 5:
          return internalGetMutableHadoopConf();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.flyteidl.plugins.SparkJob.class, com.flyteidl.plugins.SparkJob.Builder.class);
    }

    // Construct using com.flyteidl.plugins.SparkJob.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3
              .alwaysUseFieldBuilders) {
      }
    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      applicationType_ = 0;

      mainApplicationFile_ = "";

      mainClass_ = "";

      internalGetMutableSparkConf().clear();
      internalGetMutableHadoopConf().clear();
      executorPath_ = "";

      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return com.flyteidl.plugins.SparkProto.internal_static_flyteidl_plugins_SparkJob_descriptor;
    }

    @java.lang.Override
    public com.flyteidl.plugins.SparkJob getDefaultInstanceForType() {
      return com.flyteidl.plugins.SparkJob.getDefaultInstance();
    }

    @java.lang.Override
    public com.flyteidl.plugins.SparkJob build() {
      com.flyteidl.plugins.SparkJob result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public com.flyteidl.plugins.SparkJob buildPartial() {
      com.flyteidl.plugins.SparkJob result = new com.flyteidl.plugins.SparkJob(this);
      int from_bitField0_ = bitField0_;
      result.applicationType_ = applicationType_;
      result.mainApplicationFile_ = mainApplicationFile_;
      result.mainClass_ = mainClass_;
      result.sparkConf_ = internalGetSparkConf();
      result.sparkConf_.makeImmutable();
      result.hadoopConf_ = internalGetHadoopConf();
      result.hadoopConf_.makeImmutable();
      result.executorPath_ = executorPath_;
      onBuilt();
      return result;
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }
    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.setField(field, value);
    }
    @java.lang.Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @java.lang.Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }
    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.flyteidl.plugins.SparkJob) {
        return mergeFrom((com.flyteidl.plugins.SparkJob)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.flyteidl.plugins.SparkJob other) {
      if (other == com.flyteidl.plugins.SparkJob.getDefaultInstance()) return this;
      if (other.applicationType_ != 0) {
        setApplicationTypeValue(other.getApplicationTypeValue());
      }
      if (!other.getMainApplicationFile().isEmpty()) {
        mainApplicationFile_ = other.mainApplicationFile_;
        onChanged();
      }
      if (!other.getMainClass().isEmpty()) {
        mainClass_ = other.mainClass_;
        onChanged();
      }
      internalGetMutableSparkConf().mergeFrom(
          other.internalGetSparkConf());
      internalGetMutableHadoopConf().mergeFrom(
          other.internalGetHadoopConf());
      if (!other.getExecutorPath().isEmpty()) {
        executorPath_ = other.executorPath_;
        onChanged();
      }
      this.mergeUnknownFields(other.unknownFields);
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      com.flyteidl.plugins.SparkJob parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (com.flyteidl.plugins.SparkJob) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }
    private int bitField0_;

    private int applicationType_ = 0;
    /**
     * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
     * @return The enum numeric value on the wire for applicationType.
     */
    @java.lang.Override public int getApplicationTypeValue() {
      return applicationType_;
    }
    /**
     * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
     * @param value The enum numeric value on the wire for applicationType to set.
     * @return This builder for chaining.
     */
    public Builder setApplicationTypeValue(int value) {
      
      applicationType_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
     * @return The applicationType.
     */
    @java.lang.Override
    public com.flyteidl.plugins.SparkApplication.Type getApplicationType() {
      @SuppressWarnings("deprecation")
      com.flyteidl.plugins.SparkApplication.Type result = com.flyteidl.plugins.SparkApplication.Type.valueOf(applicationType_);
      return result == null ? com.flyteidl.plugins.SparkApplication.Type.UNRECOGNIZED : result;
    }
    /**
     * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
     * @param value The applicationType to set.
     * @return This builder for chaining.
     */
    public Builder setApplicationType(com.flyteidl.plugins.SparkApplication.Type value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      applicationType_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
     * @return This builder for chaining.
     */
    public Builder clearApplicationType() {
      
      applicationType_ = 0;
      onChanged();
      return this;
    }

    private java.lang.Object mainApplicationFile_ = "";
    /**
     * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
     * @return The mainApplicationFile.
     */
    public java.lang.String getMainApplicationFile() {
      java.lang.Object ref = mainApplicationFile_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        mainApplicationFile_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
     * @return The bytes for mainApplicationFile.
     */
    public com.google.protobuf.ByteString
        getMainApplicationFileBytes() {
      java.lang.Object ref = mainApplicationFile_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        mainApplicationFile_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
     * @param value The mainApplicationFile to set.
     * @return This builder for chaining.
     */
    public Builder setMainApplicationFile(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      mainApplicationFile_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
     * @return This builder for chaining.
     */
    public Builder clearMainApplicationFile() {
      
      mainApplicationFile_ = getDefaultInstance().getMainApplicationFile();
      onChanged();
      return this;
    }
    /**
     * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
     * @param value The bytes for mainApplicationFile to set.
     * @return This builder for chaining.
     */
    public Builder setMainApplicationFileBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      mainApplicationFile_ = value;
      onChanged();
      return this;
    }

    private java.lang.Object mainClass_ = "";
    /**
     * <code>string mainClass = 3 [json_name = "mainClass"];</code>
     * @return The mainClass.
     */
    public java.lang.String getMainClass() {
      java.lang.Object ref = mainClass_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        mainClass_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <code>string mainClass = 3 [json_name = "mainClass"];</code>
     * @return The bytes for mainClass.
     */
    public com.google.protobuf.ByteString
        getMainClassBytes() {
      java.lang.Object ref = mainClass_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        mainClass_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <code>string mainClass = 3 [json_name = "mainClass"];</code>
     * @param value The mainClass to set.
     * @return This builder for chaining.
     */
    public Builder setMainClass(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      mainClass_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>string mainClass = 3 [json_name = "mainClass"];</code>
     * @return This builder for chaining.
     */
    public Builder clearMainClass() {
      
      mainClass_ = getDefaultInstance().getMainClass();
      onChanged();
      return this;
    }
    /**
     * <code>string mainClass = 3 [json_name = "mainClass"];</code>
     * @param value The bytes for mainClass to set.
     * @return This builder for chaining.
     */
    public Builder setMainClassBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      mainClass_ = value;
      onChanged();
      return this;
    }

    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> sparkConf_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetSparkConf() {
      if (sparkConf_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            SparkConfDefaultEntryHolder.defaultEntry);
      }
      return sparkConf_;
    }
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetMutableSparkConf() {
      onChanged();;
      if (sparkConf_ == null) {
        sparkConf_ = com.google.protobuf.MapField.newMapField(
            SparkConfDefaultEntryHolder.defaultEntry);
      }
      if (!sparkConf_.isMutable()) {
        sparkConf_ = sparkConf_.copy();
      }
      return sparkConf_;
    }

    public int getSparkConfCount() {
      return internalGetSparkConf().getMap().size();
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */

    @java.lang.Override
    public boolean containsSparkConf(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetSparkConf().getMap().containsKey(key);
    }
    /**
     * Use {@link #getSparkConfMap()} instead.
     */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getSparkConf() {
      return getSparkConfMap();
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */
    @java.lang.Override

    public java.util.Map<java.lang.String, java.lang.String> getSparkConfMap() {
      return internalGetSparkConf().getMap();
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */
    @java.lang.Override

    public java.lang.String getSparkConfOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetSparkConf().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */
    @java.lang.Override

    public java.lang.String getSparkConfOrThrow(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetSparkConf().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public Builder clearSparkConf() {
      internalGetMutableSparkConf().getMutableMap()
          .clear();
      return this;
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */

    public Builder removeSparkConf(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      internalGetMutableSparkConf().getMutableMap()
          .remove(key);
      return this;
    }
    /**
     * Use alternate mutation accessors instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String>
    getMutableSparkConf() {
      return internalGetMutableSparkConf().getMutableMap();
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */
    public Builder putSparkConf(
        java.lang.String key,
        java.lang.String value) {
      if (key == null) { throw new NullPointerException("map key"); }
      if (value == null) {
  throw new NullPointerException("map value");
}

      internalGetMutableSparkConf().getMutableMap()
          .put(key, value);
      return this;
    }
    /**
     * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
     */

    public Builder putAllSparkConf(
        java.util.Map<java.lang.String, java.lang.String> values) {
      internalGetMutableSparkConf().getMutableMap()
          .putAll(values);
      return this;
    }

    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> hadoopConf_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetHadoopConf() {
      if (hadoopConf_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            HadoopConfDefaultEntryHolder.defaultEntry);
      }
      return hadoopConf_;
    }
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetMutableHadoopConf() {
      onChanged();;
      if (hadoopConf_ == null) {
        hadoopConf_ = com.google.protobuf.MapField.newMapField(
            HadoopConfDefaultEntryHolder.defaultEntry);
      }
      if (!hadoopConf_.isMutable()) {
        hadoopConf_ = hadoopConf_.copy();
      }
      return hadoopConf_;
    }

    public int getHadoopConfCount() {
      return internalGetHadoopConf().getMap().size();
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */

    @java.lang.Override
    public boolean containsHadoopConf(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetHadoopConf().getMap().containsKey(key);
    }
    /**
     * Use {@link #getHadoopConfMap()} instead.
     */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getHadoopConf() {
      return getHadoopConfMap();
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */
    @java.lang.Override

    public java.util.Map<java.lang.String, java.lang.String> getHadoopConfMap() {
      return internalGetHadoopConf().getMap();
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */
    @java.lang.Override

    public java.lang.String getHadoopConfOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetHadoopConf().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */
    @java.lang.Override

    public java.lang.String getHadoopConfOrThrow(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetHadoopConf().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public Builder clearHadoopConf() {
      internalGetMutableHadoopConf().getMutableMap()
          .clear();
      return this;
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */

    public Builder removeHadoopConf(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      internalGetMutableHadoopConf().getMutableMap()
          .remove(key);
      return this;
    }
    /**
     * Use alternate mutation accessors instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String>
    getMutableHadoopConf() {
      return internalGetMutableHadoopConf().getMutableMap();
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */
    public Builder putHadoopConf(
        java.lang.String key,
        java.lang.String value) {
      if (key == null) { throw new NullPointerException("map key"); }
      if (value == null) {
  throw new NullPointerException("map value");
}

      internalGetMutableHadoopConf().getMutableMap()
          .put(key, value);
      return this;
    }
    /**
     * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
     */

    public Builder putAllHadoopConf(
        java.util.Map<java.lang.String, java.lang.String> values) {
      internalGetMutableHadoopConf().getMutableMap()
          .putAll(values);
      return this;
    }

    private java.lang.Object executorPath_ = "";
    /**
     * <pre>
     * Executor path for Python jobs.
     * </pre>
     *
     * <code>string executorPath = 6 [json_name = "executorPath"];</code>
     * @return The executorPath.
     */
    public java.lang.String getExecutorPath() {
      java.lang.Object ref = executorPath_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        executorPath_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * Executor path for Python jobs.
     * </pre>
     *
     * <code>string executorPath = 6 [json_name = "executorPath"];</code>
     * @return The bytes for executorPath.
     */
    public com.google.protobuf.ByteString
        getExecutorPathBytes() {
      java.lang.Object ref = executorPath_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        executorPath_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Executor path for Python jobs.
     * </pre>
     *
     * <code>string executorPath = 6 [json_name = "executorPath"];</code>
     * @param value The executorPath to set.
     * @return This builder for chaining.
     */
    public Builder setExecutorPath(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      executorPath_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Executor path for Python jobs.
     * </pre>
     *
     * <code>string executorPath = 6 [json_name = "executorPath"];</code>
     * @return This builder for chaining.
     */
    public Builder clearExecutorPath() {
      
      executorPath_ = getDefaultInstance().getExecutorPath();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Executor path for Python jobs.
     * </pre>
     *
     * <code>string executorPath = 6 [json_name = "executorPath"];</code>
     * @param value The bytes for executorPath to set.
     * @return This builder for chaining.
     */
    public Builder setExecutorPathBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      executorPath_ = value;
      onChanged();
      return this;
    }
    @java.lang.Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:flyteidl.plugins.SparkJob)
  }

  // @@protoc_insertion_point(class_scope:flyteidl.plugins.SparkJob)
  private static final com.flyteidl.plugins.SparkJob DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new com.flyteidl.plugins.SparkJob();
  }

  public static com.flyteidl.plugins.SparkJob getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<SparkJob>
      PARSER = new com.google.protobuf.AbstractParser<SparkJob>() {
    @java.lang.Override
    public SparkJob parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return new SparkJob(input, extensionRegistry);
    }
  };

  public static com.google.protobuf.Parser<SparkJob> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<SparkJob> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public com.flyteidl.plugins.SparkJob getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

