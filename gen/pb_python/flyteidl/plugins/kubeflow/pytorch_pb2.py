# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: flyteidl/plugins/kubeflow/pytorch.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from flyteidl.core import tasks_pb2 as flyteidl_dot_core_dot_tasks__pb2
from flyteidl.plugins.kubeflow import common_pb2 as flyteidl_dot_plugins_dot_kubeflow_dot_common__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='flyteidl/plugins/kubeflow/pytorch.proto',
  package='flyteidl.plugins.kubeflow',
  syntax='proto3',
  serialized_options=_b('Z7github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/plugins'),
  serialized_pb=_b('\n\'flyteidl/plugins/kubeflow/pytorch.proto\x12\x19\x66lyteidl.plugins.kubeflow\x1a\x19\x66lyteidl/core/tasks.proto\x1a&flyteidl/plugins/kubeflow/common.proto\"\x7f\n\rElasticConfig\x12\x14\n\x0crdzv_backend\x18\x01 \x01(\t\x12\x14\n\x0cmin_replicas\x18\x02 \x01(\x05\x12\x14\n\x0cmax_replicas\x18\x03 \x01(\x05\x12\x16\n\x0enproc_per_node\x18\x04 \x01(\x05\x12\x14\n\x0cmax_restarts\x18\x05 \x01(\x05\"\xd2\x02\n\x1e\x44istributedPyTorchTrainingTask\x12Y\n\x0fworker_replicas\x18\x01 \x01(\x0b\x32@.flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec\x12Y\n\x0fmaster_replicas\x18\x02 \x01(\x0b\x32@.flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec\x12\x38\n\nrun_policy\x18\x03 \x01(\x0b\x32$.flyteidl.plugins.kubeflow.RunPolicy\x12@\n\x0e\x65lastic_config\x18\x04 \x01(\x0b\x32(.flyteidl.plugins.kubeflow.ElasticConfig\"\xb7\x01\n%DistributedPyTorchTrainingReplicaSpec\x12\x10\n\x08replicas\x18\x01 \x01(\x05\x12\r\n\x05image\x18\x02 \x01(\t\x12+\n\tresources\x18\x03 \x01(\x0b\x32\x18.flyteidl.core.Resources\x12@\n\x0erestart_policy\x18\x04 \x01(\x0e\x32(.flyteidl.plugins.kubeflow.RestartPolicyB9Z7github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/pluginsb\x06proto3')
  ,
  dependencies=[flyteidl_dot_core_dot_tasks__pb2.DESCRIPTOR,flyteidl_dot_plugins_dot_kubeflow_dot_common__pb2.DESCRIPTOR,])




_ELASTICCONFIG = _descriptor.Descriptor(
  name='ElasticConfig',
  full_name='flyteidl.plugins.kubeflow.ElasticConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='rdzv_backend', full_name='flyteidl.plugins.kubeflow.ElasticConfig.rdzv_backend', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='min_replicas', full_name='flyteidl.plugins.kubeflow.ElasticConfig.min_replicas', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='max_replicas', full_name='flyteidl.plugins.kubeflow.ElasticConfig.max_replicas', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='nproc_per_node', full_name='flyteidl.plugins.kubeflow.ElasticConfig.nproc_per_node', index=3,
      number=4, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='max_restarts', full_name='flyteidl.plugins.kubeflow.ElasticConfig.max_restarts', index=4,
      number=5, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=137,
  serialized_end=264,
)


_DISTRIBUTEDPYTORCHTRAININGTASK = _descriptor.Descriptor(
  name='DistributedPyTorchTrainingTask',
  full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingTask',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='worker_replicas', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingTask.worker_replicas', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='master_replicas', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingTask.master_replicas', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='run_policy', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingTask.run_policy', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='elastic_config', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingTask.elastic_config', index=3,
      number=4, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=267,
  serialized_end=605,
)


_DISTRIBUTEDPYTORCHTRAININGREPLICASPEC = _descriptor.Descriptor(
  name='DistributedPyTorchTrainingReplicaSpec',
  full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='replicas', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec.replicas', index=0,
      number=1, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='image', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec.image', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='resources', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec.resources', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='restart_policy', full_name='flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec.restart_policy', index=3,
      number=4, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=608,
  serialized_end=791,
)

_DISTRIBUTEDPYTORCHTRAININGTASK.fields_by_name['worker_replicas'].message_type = _DISTRIBUTEDPYTORCHTRAININGREPLICASPEC
_DISTRIBUTEDPYTORCHTRAININGTASK.fields_by_name['master_replicas'].message_type = _DISTRIBUTEDPYTORCHTRAININGREPLICASPEC
_DISTRIBUTEDPYTORCHTRAININGTASK.fields_by_name['run_policy'].message_type = flyteidl_dot_plugins_dot_kubeflow_dot_common__pb2._RUNPOLICY
_DISTRIBUTEDPYTORCHTRAININGTASK.fields_by_name['elastic_config'].message_type = _ELASTICCONFIG
_DISTRIBUTEDPYTORCHTRAININGREPLICASPEC.fields_by_name['resources'].message_type = flyteidl_dot_core_dot_tasks__pb2._RESOURCES
_DISTRIBUTEDPYTORCHTRAININGREPLICASPEC.fields_by_name['restart_policy'].enum_type = flyteidl_dot_plugins_dot_kubeflow_dot_common__pb2._RESTARTPOLICY
DESCRIPTOR.message_types_by_name['ElasticConfig'] = _ELASTICCONFIG
DESCRIPTOR.message_types_by_name['DistributedPyTorchTrainingTask'] = _DISTRIBUTEDPYTORCHTRAININGTASK
DESCRIPTOR.message_types_by_name['DistributedPyTorchTrainingReplicaSpec'] = _DISTRIBUTEDPYTORCHTRAININGREPLICASPEC
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

ElasticConfig = _reflection.GeneratedProtocolMessageType('ElasticConfig', (_message.Message,), dict(
  DESCRIPTOR = _ELASTICCONFIG,
  __module__ = 'flyteidl.plugins.kubeflow.pytorch_pb2'
  # @@protoc_insertion_point(class_scope:flyteidl.plugins.kubeflow.ElasticConfig)
  ))
_sym_db.RegisterMessage(ElasticConfig)

DistributedPyTorchTrainingTask = _reflection.GeneratedProtocolMessageType('DistributedPyTorchTrainingTask', (_message.Message,), dict(
  DESCRIPTOR = _DISTRIBUTEDPYTORCHTRAININGTASK,
  __module__ = 'flyteidl.plugins.kubeflow.pytorch_pb2'
  # @@protoc_insertion_point(class_scope:flyteidl.plugins.kubeflow.DistributedPyTorchTrainingTask)
  ))
_sym_db.RegisterMessage(DistributedPyTorchTrainingTask)

DistributedPyTorchTrainingReplicaSpec = _reflection.GeneratedProtocolMessageType('DistributedPyTorchTrainingReplicaSpec', (_message.Message,), dict(
  DESCRIPTOR = _DISTRIBUTEDPYTORCHTRAININGREPLICASPEC,
  __module__ = 'flyteidl.plugins.kubeflow.pytorch_pb2'
  # @@protoc_insertion_point(class_scope:flyteidl.plugins.kubeflow.DistributedPyTorchTrainingReplicaSpec)
  ))
_sym_db.RegisterMessage(DistributedPyTorchTrainingReplicaSpec)


DESCRIPTOR._options = None
# @@protoc_insertion_point(module_scope)
