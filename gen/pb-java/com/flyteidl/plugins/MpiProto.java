// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: flyteidl/plugins/mpi.proto

package com.flyteidl.plugins;

public final class MpiProto {
  private MpiProto() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface DistributedMPITrainingTaskOrBuilder extends
      // @@protoc_insertion_point(interface_extends:flyteidl.plugins.DistributedMPITrainingTask)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * number of worker spawned in the cluster for this job
     * </pre>
     *
     * <code>int32 num_workers = 1 [json_name = "numWorkers"];</code>
     * @return The numWorkers.
     */
    int getNumWorkers();

    /**
     * <pre>
     * number of launcher replicas spawned in the cluster for this job
     * The launcher pod invokes mpirun and communicates with worker pods through MPI.
     * </pre>
     *
     * <code>int32 num_launcher_replicas = 2 [json_name = "numLauncherReplicas"];</code>
     * @return The numLauncherReplicas.
     */
    int getNumLauncherReplicas();

    /**
     * <pre>
     * number of slots per worker used in hostfile.
     * The available slots (GPUs) in each pod.
     * </pre>
     *
     * <code>int32 slots = 3 [json_name = "slots"];</code>
     * @return The slots.
     */
    int getSlots();
  }
  /**
   * <pre>
   * MPI operator proposal https://github.com/kubeflow/community/blob/master/proposals/mpi-operator-proposal.md
   * Custom proto for plugin that enables distributed training using https://github.com/kubeflow/mpi-operator
   * </pre>
   *
   * Protobuf type {@code flyteidl.plugins.DistributedMPITrainingTask}
   */
  public static final class DistributedMPITrainingTask extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:flyteidl.plugins.DistributedMPITrainingTask)
      DistributedMPITrainingTaskOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DistributedMPITrainingTask.newBuilder() to construct.
    private DistributedMPITrainingTask(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DistributedMPITrainingTask() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DistributedMPITrainingTask();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.flyteidl.plugins.MpiProto.internal_static_flyteidl_plugins_DistributedMPITrainingTask_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.flyteidl.plugins.MpiProto.internal_static_flyteidl_plugins_DistributedMPITrainingTask_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask.class, com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask.Builder.class);
    }

    public static final int NUM_WORKERS_FIELD_NUMBER = 1;
    private int numWorkers_;
    /**
     * <pre>
     * number of worker spawned in the cluster for this job
     * </pre>
     *
     * <code>int32 num_workers = 1 [json_name = "numWorkers"];</code>
     * @return The numWorkers.
     */
    @java.lang.Override
    public int getNumWorkers() {
      return numWorkers_;
    }

    public static final int NUM_LAUNCHER_REPLICAS_FIELD_NUMBER = 2;
    private int numLauncherReplicas_;
    /**
     * <pre>
     * number of launcher replicas spawned in the cluster for this job
     * The launcher pod invokes mpirun and communicates with worker pods through MPI.
     * </pre>
     *
     * <code>int32 num_launcher_replicas = 2 [json_name = "numLauncherReplicas"];</code>
     * @return The numLauncherReplicas.
     */
    @java.lang.Override
    public int getNumLauncherReplicas() {
      return numLauncherReplicas_;
    }

    public static final int SLOTS_FIELD_NUMBER = 3;
    private int slots_;
    /**
     * <pre>
     * number of slots per worker used in hostfile.
     * The available slots (GPUs) in each pod.
     * </pre>
     *
     * <code>int32 slots = 3 [json_name = "slots"];</code>
     * @return The slots.
     */
    @java.lang.Override
    public int getSlots() {
      return slots_;
    }

    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * MPI operator proposal https://github.com/kubeflow/community/blob/master/proposals/mpi-operator-proposal.md
     * Custom proto for plugin that enables distributed training using https://github.com/kubeflow/mpi-operator
     * </pre>
     *
     * Protobuf type {@code flyteidl.plugins.DistributedMPITrainingTask}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:flyteidl.plugins.DistributedMPITrainingTask)
        com.flyteidl.plugins.MpiProto.DistributedMPITrainingTaskOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.flyteidl.plugins.MpiProto.internal_static_flyteidl_plugins_DistributedMPITrainingTask_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.flyteidl.plugins.MpiProto.internal_static_flyteidl_plugins_DistributedMPITrainingTask_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask.class, com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask.Builder.class);
      }

      // Construct using com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        numWorkers_ = 0;

        numLauncherReplicas_ = 0;

        slots_ = 0;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.flyteidl.plugins.MpiProto.internal_static_flyteidl_plugins_DistributedMPITrainingTask_descriptor;
      }

      @java.lang.Override
      public com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask getDefaultInstanceForType() {
        return com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask.getDefaultInstance();
      }

      @java.lang.Override
      public com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask build() {
        com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask buildPartial() {
        com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask result = new com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask(this);
        result.numWorkers_ = numWorkers_;
        result.numLauncherReplicas_ = numLauncherReplicas_;
        result.slots_ = slots_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }

      private int numWorkers_ ;
      /**
       * <pre>
       * number of worker spawned in the cluster for this job
       * </pre>
       *
       * <code>int32 num_workers = 1 [json_name = "numWorkers"];</code>
       * @return The numWorkers.
       */
      @java.lang.Override
      public int getNumWorkers() {
        return numWorkers_;
      }
      /**
       * <pre>
       * number of worker spawned in the cluster for this job
       * </pre>
       *
       * <code>int32 num_workers = 1 [json_name = "numWorkers"];</code>
       * @param value The numWorkers to set.
       * @return This builder for chaining.
       */
      public Builder setNumWorkers(int value) {
        
        numWorkers_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * number of worker spawned in the cluster for this job
       * </pre>
       *
       * <code>int32 num_workers = 1 [json_name = "numWorkers"];</code>
       * @return This builder for chaining.
       */
      public Builder clearNumWorkers() {
        
        numWorkers_ = 0;
        onChanged();
        return this;
      }

      private int numLauncherReplicas_ ;
      /**
       * <pre>
       * number of launcher replicas spawned in the cluster for this job
       * The launcher pod invokes mpirun and communicates with worker pods through MPI.
       * </pre>
       *
       * <code>int32 num_launcher_replicas = 2 [json_name = "numLauncherReplicas"];</code>
       * @return The numLauncherReplicas.
       */
      @java.lang.Override
      public int getNumLauncherReplicas() {
        return numLauncherReplicas_;
      }
      /**
       * <pre>
       * number of launcher replicas spawned in the cluster for this job
       * The launcher pod invokes mpirun and communicates with worker pods through MPI.
       * </pre>
       *
       * <code>int32 num_launcher_replicas = 2 [json_name = "numLauncherReplicas"];</code>
       * @param value The numLauncherReplicas to set.
       * @return This builder for chaining.
       */
      public Builder setNumLauncherReplicas(int value) {
        
        numLauncherReplicas_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * number of launcher replicas spawned in the cluster for this job
       * The launcher pod invokes mpirun and communicates with worker pods through MPI.
       * </pre>
       *
       * <code>int32 num_launcher_replicas = 2 [json_name = "numLauncherReplicas"];</code>
       * @return This builder for chaining.
       */
      public Builder clearNumLauncherReplicas() {
        
        numLauncherReplicas_ = 0;
        onChanged();
        return this;
      }

      private int slots_ ;
      /**
       * <pre>
       * number of slots per worker used in hostfile.
       * The available slots (GPUs) in each pod.
       * </pre>
       *
       * <code>int32 slots = 3 [json_name = "slots"];</code>
       * @return The slots.
       */
      @java.lang.Override
      public int getSlots() {
        return slots_;
      }
      /**
       * <pre>
       * number of slots per worker used in hostfile.
       * The available slots (GPUs) in each pod.
       * </pre>
       *
       * <code>int32 slots = 3 [json_name = "slots"];</code>
       * @param value The slots to set.
       * @return This builder for chaining.
       */
      public Builder setSlots(int value) {
        
        slots_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * number of slots per worker used in hostfile.
       * The available slots (GPUs) in each pod.
       * </pre>
       *
       * <code>int32 slots = 3 [json_name = "slots"];</code>
       * @return This builder for chaining.
       */
      public Builder clearSlots() {
        
        slots_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:flyteidl.plugins.DistributedMPITrainingTask)
    }

    // @@protoc_insertion_point(class_scope:flyteidl.plugins.DistributedMPITrainingTask)
    private static final com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask();
    }

    public static com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<DistributedMPITrainingTask>
        PARSER = new com.google.protobuf.AbstractParser<DistributedMPITrainingTask>() {
      @java.lang.Override
      public DistributedMPITrainingTask parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e.getMessage()).setUnfinishedMessage(
                  builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<DistributedMPITrainingTask> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DistributedMPITrainingTask> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.flyteidl.plugins.MpiProto.DistributedMPITrainingTask getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_flyteidl_plugins_DistributedMPITrainingTask_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_flyteidl_plugins_DistributedMPITrainingTask_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\032flyteidl/plugins/mpi.proto\022\020flyteidl.p" +
      "lugins\"\207\001\n\032DistributedMPITrainingTask\022\037\n" +
      "\013num_workers\030\001 \001(\005R\nnumWorkers\0222\n\025num_la" +
      "uncher_replicas\030\002 \001(\005R\023numLauncherReplic" +
      "as\022\024\n\005slots\030\003 \001(\005R\005slotsB\275\001\n\024com.flyteid" +
      "l.pluginsB\010MpiProtoH\002Z7github.com/flyteo" +
      "rg/flyteidl/gen/pb-go/flyteidl/plugins\370\001" +
      "\000\242\002\003FPX\252\002\020Flyteidl.Plugins\312\002\020Flyteidl\\Pl" +
      "ugins\342\002\034Flyteidl\\Plugins\\GPBMetadata\352\002\021F" +
      "lyteidl::Pluginsb\006proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        });
    internal_static_flyteidl_plugins_DistributedMPITrainingTask_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_flyteidl_plugins_DistributedMPITrainingTask_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_flyteidl_plugins_DistributedMPITrainingTask_descriptor,
        new java.lang.String[] { "NumWorkers", "NumLauncherReplicas", "Slots", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
