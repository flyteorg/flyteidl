// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: flyteidl/plugins/spark.proto

package com.flyteidl.plugins;

public interface SparkJobOrBuilder extends
    // @@protoc_insertion_point(interface_extends:flyteidl.plugins.SparkJob)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
   * @return The enum numeric value on the wire for applicationType.
   */
  int getApplicationTypeValue();
  /**
   * <code>.flyteidl.plugins.SparkApplication.Type applicationType = 1 [json_name = "applicationType"];</code>
   * @return The applicationType.
   */
  com.flyteidl.plugins.SparkApplication.Type getApplicationType();

  /**
   * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
   * @return The mainApplicationFile.
   */
  java.lang.String getMainApplicationFile();
  /**
   * <code>string mainApplicationFile = 2 [json_name = "mainApplicationFile"];</code>
   * @return The bytes for mainApplicationFile.
   */
  com.google.protobuf.ByteString
      getMainApplicationFileBytes();

  /**
   * <code>string mainClass = 3 [json_name = "mainClass"];</code>
   * @return The mainClass.
   */
  java.lang.String getMainClass();
  /**
   * <code>string mainClass = 3 [json_name = "mainClass"];</code>
   * @return The bytes for mainClass.
   */
  com.google.protobuf.ByteString
      getMainClassBytes();

  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */
  int getSparkConfCount();
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */
  boolean containsSparkConf(
      java.lang.String key);
  /**
   * Use {@link #getSparkConfMap()} instead.
   */
  @java.lang.Deprecated
  java.util.Map<java.lang.String, java.lang.String>
  getSparkConf();
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */
  java.util.Map<java.lang.String, java.lang.String>
  getSparkConfMap();
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */

  java.lang.String getSparkConfOrDefault(
      java.lang.String key,
      java.lang.String defaultValue);
  /**
   * <code>map&lt;string, string&gt; sparkConf = 4 [json_name = "sparkConf"];</code>
   */

  java.lang.String getSparkConfOrThrow(
      java.lang.String key);

  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */
  int getHadoopConfCount();
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */
  boolean containsHadoopConf(
      java.lang.String key);
  /**
   * Use {@link #getHadoopConfMap()} instead.
   */
  @java.lang.Deprecated
  java.util.Map<java.lang.String, java.lang.String>
  getHadoopConf();
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */
  java.util.Map<java.lang.String, java.lang.String>
  getHadoopConfMap();
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */

  java.lang.String getHadoopConfOrDefault(
      java.lang.String key,
      java.lang.String defaultValue);
  /**
   * <code>map&lt;string, string&gt; hadoopConf = 5 [json_name = "hadoopConf"];</code>
   */

  java.lang.String getHadoopConfOrThrow(
      java.lang.String key);

  /**
   * <pre>
   * Executor path for Python jobs.
   * </pre>
   *
   * <code>string executorPath = 6 [json_name = "executorPath"];</code>
   * @return The executorPath.
   */
  java.lang.String getExecutorPath();
  /**
   * <pre>
   * Executor path for Python jobs.
   * </pre>
   *
   * <code>string executorPath = 6 [json_name = "executorPath"];</code>
   * @return The bytes for executorPath.
   */
  com.google.protobuf.ByteString
      getExecutorPathBytes();
}
