// source: flyteidl/plugins/spark.proto
/**
 * @fileoverview
 * @enhanceable
 * @suppress {missingRequire} reports error on implicit type usages.
 * @suppress {messageConventions} JS Compiler reports an error if a variable or
 *     field starts with 'MSG_' and isn't a translatable message.
 * @public
 */
// GENERATED CODE -- DO NOT EDIT!
/* eslint-disable */
// @ts-nocheck

goog.provide('proto.flyteidl.plugins.SparkJob');

goog.require('jspb.BinaryReader');
goog.require('jspb.BinaryWriter');
goog.require('jspb.Map');
goog.require('jspb.Message');

goog.forwardDeclare('proto.flyteidl.plugins.SparkApplication.Type');
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.flyteidl.plugins.SparkJob = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, null, null);
};
goog.inherits(proto.flyteidl.plugins.SparkJob, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.flyteidl.plugins.SparkJob.displayName = 'proto.flyteidl.plugins.SparkJob';
}



if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.flyteidl.plugins.SparkJob.prototype.toObject = function(opt_includeInstance) {
  return proto.flyteidl.plugins.SparkJob.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.flyteidl.plugins.SparkJob} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.flyteidl.plugins.SparkJob.toObject = function(includeInstance, msg) {
  var f, obj = {
    applicationtype: jspb.Message.getFieldWithDefault(msg, 1, 0),
    mainapplicationfile: jspb.Message.getFieldWithDefault(msg, 2, ""),
    mainclass: jspb.Message.getFieldWithDefault(msg, 3, ""),
    sparkconfMap: (f = msg.getSparkconfMap()) ? f.toObject(includeInstance, undefined) : [],
    hadoopconfMap: (f = msg.getHadoopconfMap()) ? f.toObject(includeInstance, undefined) : [],
    executorpath: jspb.Message.getFieldWithDefault(msg, 6, "")
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.flyteidl.plugins.SparkJob}
 */
proto.flyteidl.plugins.SparkJob.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.flyteidl.plugins.SparkJob;
  return proto.flyteidl.plugins.SparkJob.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.flyteidl.plugins.SparkJob} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.flyteidl.plugins.SparkJob}
 */
proto.flyteidl.plugins.SparkJob.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = /** @type {!proto.flyteidl.plugins.SparkApplication.Type} */ (reader.readEnum());
      msg.setApplicationtype(value);
      break;
    case 2:
      var value = /** @type {string} */ (reader.readString());
      msg.setMainapplicationfile(value);
      break;
    case 3:
      var value = /** @type {string} */ (reader.readString());
      msg.setMainclass(value);
      break;
    case 4:
      var value = msg.getSparkconfMap();
      reader.readMessage(value, function(message, reader) {
        jspb.Map.deserializeBinary(message, reader, jspb.BinaryReader.prototype.readString, jspb.BinaryReader.prototype.readString, null, "", "");
         });
      break;
    case 5:
      var value = msg.getHadoopconfMap();
      reader.readMessage(value, function(message, reader) {
        jspb.Map.deserializeBinary(message, reader, jspb.BinaryReader.prototype.readString, jspb.BinaryReader.prototype.readString, null, "", "");
         });
      break;
    case 6:
      var value = /** @type {string} */ (reader.readString());
      msg.setExecutorpath(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.flyteidl.plugins.SparkJob.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.flyteidl.plugins.SparkJob.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.flyteidl.plugins.SparkJob} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.flyteidl.plugins.SparkJob.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getApplicationtype();
  if (f !== 0.0) {
    writer.writeEnum(
      1,
      f
    );
  }
  f = message.getMainapplicationfile();
  if (f.length > 0) {
    writer.writeString(
      2,
      f
    );
  }
  f = message.getMainclass();
  if (f.length > 0) {
    writer.writeString(
      3,
      f
    );
  }
  f = message.getSparkconfMap(true);
  if (f && f.getLength() > 0) {
    f.serializeBinary(4, writer, jspb.BinaryWriter.prototype.writeString, jspb.BinaryWriter.prototype.writeString);
  }
  f = message.getHadoopconfMap(true);
  if (f && f.getLength() > 0) {
    f.serializeBinary(5, writer, jspb.BinaryWriter.prototype.writeString, jspb.BinaryWriter.prototype.writeString);
  }
  f = message.getExecutorpath();
  if (f.length > 0) {
    writer.writeString(
      6,
      f
    );
  }
};


/**
 * optional SparkApplication.Type applicationType = 1;
 * @return {!proto.flyteidl.plugins.SparkApplication.Type}
 */
proto.flyteidl.plugins.SparkJob.prototype.getApplicationtype = function() {
  return /** @type {!proto.flyteidl.plugins.SparkApplication.Type} */ (jspb.Message.getFieldWithDefault(this, 1, 0));
};


/**
 * @param {!proto.flyteidl.plugins.SparkApplication.Type} value
 * @return {!proto.flyteidl.plugins.SparkJob} returns this
 */
proto.flyteidl.plugins.SparkJob.prototype.setApplicationtype = function(value) {
  return jspb.Message.setProto3EnumField(this, 1, value);
};


/**
 * optional string mainApplicationFile = 2;
 * @return {string}
 */
proto.flyteidl.plugins.SparkJob.prototype.getMainapplicationfile = function() {
  return /** @type {string} */ (jspb.Message.getFieldWithDefault(this, 2, ""));
};


/**
 * @param {string} value
 * @return {!proto.flyteidl.plugins.SparkJob} returns this
 */
proto.flyteidl.plugins.SparkJob.prototype.setMainapplicationfile = function(value) {
  return jspb.Message.setProto3StringField(this, 2, value);
};


/**
 * optional string mainClass = 3;
 * @return {string}
 */
proto.flyteidl.plugins.SparkJob.prototype.getMainclass = function() {
  return /** @type {string} */ (jspb.Message.getFieldWithDefault(this, 3, ""));
};


/**
 * @param {string} value
 * @return {!proto.flyteidl.plugins.SparkJob} returns this
 */
proto.flyteidl.plugins.SparkJob.prototype.setMainclass = function(value) {
  return jspb.Message.setProto3StringField(this, 3, value);
};


/**
 * map<string, string> sparkConf = 4;
 * @param {boolean=} opt_noLazyCreate Do not create the map if
 * empty, instead returning `undefined`
 * @return {!jspb.Map<string,string>}
 */
proto.flyteidl.plugins.SparkJob.prototype.getSparkconfMap = function(opt_noLazyCreate) {
  return /** @type {!jspb.Map<string,string>} */ (
      jspb.Message.getMapField(this, 4, opt_noLazyCreate,
      null));
};


/**
 * Clears values from the map. The map will be non-null.
 * @return {!proto.flyteidl.plugins.SparkJob} returns this
 */
proto.flyteidl.plugins.SparkJob.prototype.clearSparkconfMap = function() {
  this.getSparkconfMap().clear();
  return this;};


/**
 * map<string, string> hadoopConf = 5;
 * @param {boolean=} opt_noLazyCreate Do not create the map if
 * empty, instead returning `undefined`
 * @return {!jspb.Map<string,string>}
 */
proto.flyteidl.plugins.SparkJob.prototype.getHadoopconfMap = function(opt_noLazyCreate) {
  return /** @type {!jspb.Map<string,string>} */ (
      jspb.Message.getMapField(this, 5, opt_noLazyCreate,
      null));
};


/**
 * Clears values from the map. The map will be non-null.
 * @return {!proto.flyteidl.plugins.SparkJob} returns this
 */
proto.flyteidl.plugins.SparkJob.prototype.clearHadoopconfMap = function() {
  this.getHadoopconfMap().clear();
  return this;};


/**
 * optional string executorPath = 6;
 * @return {string}
 */
proto.flyteidl.plugins.SparkJob.prototype.getExecutorpath = function() {
  return /** @type {string} */ (jspb.Message.getFieldWithDefault(this, 6, ""));
};


/**
 * @param {string} value
 * @return {!proto.flyteidl.plugins.SparkJob} returns this
 */
proto.flyteidl.plugins.SparkJob.prototype.setExecutorpath = function(value) {
  return jspb.Message.setProto3StringField(this, 6, value);
};


